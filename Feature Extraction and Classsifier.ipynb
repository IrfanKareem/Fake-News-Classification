{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iwx499921\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data as pandas dataframe\n",
    "frame=pd.read_excel('Train_set.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This man claims to be Pakistan's answer to the...</td>\n",
       "      <td>This man claims to be Pakistan's answer to the...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grade 20 officer steals Kuwaiti delegate’s wal...</td>\n",
       "      <td>ISLAMABAD: The government was exposed to extre...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paid day-to-day expenses of PM House from my o...</td>\n",
       "      <td>Incarcerated former prime minister Nawaz Shari...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rimal Khan and Her Alleged Relation With Imran...</td>\n",
       "      <td>Rimal Ali, a female Transgender disowned by fa...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Major oil find near Pak-Iran border</td>\n",
       "      <td>KARACHI: Minister for Maritime Affairs and For...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  This man claims to be Pakistan's answer to the...   \n",
       "1  Grade 20 officer steals Kuwaiti delegate’s wal...   \n",
       "2  Paid day-to-day expenses of PM House from my o...   \n",
       "3  Rimal Khan and Her Alleged Relation With Imran...   \n",
       "4                Major oil find near Pak-Iran border   \n",
       "\n",
       "                                                text label  \n",
       "0  This man claims to be Pakistan's answer to the...  Fake  \n",
       "1  ISLAMABAD: The government was exposed to extre...  Fake  \n",
       "2  Incarcerated former prime minister Nawaz Shari...  Fake  \n",
       "3  Rimal Ali, a female Transgender disowned by fa...  Fake  \n",
       "4  KARACHI: Minister for Maritime Affairs and For...  Fake  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Fake\n",
       "1    Fake\n",
       "2    Fake\n",
       "3    Fake\n",
       "4    Fake\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = frame.label\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(frame['text'], y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337    United States President Donald Trump and China...\n",
       "174    A CLEAR message of unity has been sent out by ...\n",
       "343    US Secretary of State Mike Pompeo telephoned P...\n",
       "66     Murtaza Wahab, Adviser to Sindh Chief Minister...\n",
       "202    Prime Minister Imran Khan has ordered razing w...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337    True \n",
       "174    True \n",
       "343     Fake\n",
       "66     True \n",
       "202    True \n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data.\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the `tfidf_vectorizer` \n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7) \n",
    "\n",
    "# Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8083)\t0.08482154912083911\n",
      "  (0, 7973)\t0.11686326976317357\n",
      "  (0, 7847)\t0.08209920440765768\n",
      "  (0, 7764)\t0.18696383930538085\n",
      "  (0, 7516)\t0.10749166724599923\n",
      "  (0, 7465)\t0.06092077904484056\n",
      "  (0, 7049)\t0.09147080692483202\n",
      "  (0, 7046)\t0.08342031915787501\n",
      "  (0, 6719)\t0.19624012945764982\n",
      "  (0, 6561)\t0.06712009082142824\n",
      "  (0, 6326)\t0.12351252756716646\n",
      "  (0, 6216)\t0.08962076255427016\n",
      "  (0, 6096)\t0.11686326976317357\n",
      "  (0, 6009)\t0.09568484440035645\n",
      "  (0, 5737)\t0.047912999543699625\n",
      "  (0, 5712)\t0.08631324188318212\n",
      "  (0, 5678)\t0.11170570472152366\n",
      "  (0, 5415)\t0.04880781641585067\n",
      "  (0, 5319)\t0.23899195223756767\n",
      "  (0, 5280)\t0.20168481888401266\n",
      "  (0, 5154)\t0.11686326976317357\n",
      "  (0, 5011)\t0.10749166724599923\n",
      "  (0, 4952)\t0.1405847631240298\n",
      "  (0, 4940)\t0.26576826016868155\n",
      "  (0, 4871)\t0.07272760189048337\n",
      "  :\t:\n",
      "  (113, 1257)\t0.04321297281075771\n",
      "  (113, 1202)\t0.03846648475561793\n",
      "  (113, 1179)\t0.04178063596927824\n",
      "  (113, 1171)\t0.04490706772545101\n",
      "  (113, 1154)\t0.13472120317635303\n",
      "  (113, 1113)\t0.04490706772545101\n",
      "  (113, 1078)\t0.04321297281075771\n",
      "  (113, 935)\t0.03072726217339392\n",
      "  (113, 928)\t0.07693296951123586\n",
      "  (113, 916)\t0.04490706772545101\n",
      "  (113, 897)\t0.1183364198718662\n",
      "  (113, 894)\t0.07354477968184928\n",
      "  (113, 890)\t0.036028649241006086\n",
      "  (113, 889)\t0.04321297281075771\n",
      "  (113, 818)\t0.04321297281075771\n",
      "  (113, 817)\t0.13414397882150825\n",
      "  (113, 796)\t0.04490706772545101\n",
      "  (113, 757)\t0.03846648475561793\n",
      "  (113, 563)\t0.04178063596927824\n",
      "  (113, 540)\t0.03300489032078899\n",
      "  (113, 507)\t0.040539889361060275\n",
      "  (113, 400)\t0.034099306391227206\n",
      "  (113, 395)\t0.04490706772545101\n",
      "  (113, 369)\t0.06405180357156973\n",
      "  (113, 119)\t0.031572553479309526\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zone', 'zones', 'zoological', 'zor', 'zsl', 'zubair', 'zuckerberg', 'zulfi', 'zulfikar', 'zulfiqar']\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names of `tfidf_vectorizer` \n",
    "print(tfidf_vectorizer.get_feature_names()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '000ft', '01', '025', '049', '09', '0yk', '10', '100']\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names of `count_vectorizer` \n",
    "print(count_vectorizer.get_feature_names()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000ft</th>\n",
       "      <th>01</th>\n",
       "      <th>025</th>\n",
       "      <th>049</th>\n",
       "      <th>09</th>\n",
       "      <th>0yk</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zor</th>\n",
       "      <th>zsl</th>\n",
       "      <th>zubair</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zulfi</th>\n",
       "      <th>zulfikar</th>\n",
       "      <th>zulfiqar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000ft  01  025  049  09  0yk  10  100    ...     zone  zones  \\\n",
       "0   0    0      0   0    0    0   0    0   4    0    ...        0      0   \n",
       "1   0    0      0   0    0    0   0    0   0    0    ...        0      0   \n",
       "2   0    0      0   0    0    0   0    0   0    0    ...        0      0   \n",
       "3   0    0      0   0    0    0   0    0   0    0    ...        0      0   \n",
       "4   0    0      0   0    0    0   0    0   0    0    ...        0      0   \n",
       "\n",
       "   zoological  zor  zsl  zubair  zuckerberg  zulfi  zulfikar  zulfiqar  \n",
       "0           0    0    0       0           0      0         0         0  \n",
       "1           0    0    0       0           0      0         0         0  \n",
       "2           0    0    0       0           0      0         0         0  \n",
       "3           0    0    0       0           0      0         0         0  \n",
       "4           0    0    0       0           0      0         0         0  \n",
       "\n",
       "[5 rows x 8294 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "difference\n",
    "set()\n",
    "print(count_df.equals(tfidf_df))\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.702\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "clf.fit(tfidf_train, y_train)\n",
    "pred = clf.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "#cm = confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\n",
    "#plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.702\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "clf.fit(count_train, y_train)\n",
    "pred = clf.predict(count_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "#cm = confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\n",
    "#plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iwx499921\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_clf = PassiveAggressiveClassifier(n_iter=50)\n",
    "linear_clf.fit(tfidf_train, y_train)\n",
    "pred = linear_clf.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "#cm = confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\n",
    "#plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake -2.7035907991957076 rainfall\n",
      "Fake -2.401348042042769 tlv\n",
      "Fake -2.167448370705674 bisp\n",
      "Fake -2.1088987521870526 flooded\n",
      "Fake -2.0444607605555123 scharf\n",
      "Fake -1.9088310058191869 asked\n",
      "Fake -1.746638532693724 flew\n",
      "Fake -1.7255318309363212 week\n",
      "Fake -1.6409591937064505 stated\n",
      "Fake -1.6051559136939335 release\n",
      "Fake -1.5942175960741456 nawaz\n",
      "Fake -1.5895347847308166 verify\n",
      "Fake -1.5403799377438503 new\n",
      "Fake -1.5269868296532525 tweet\n",
      "Fake -1.3736276302231138 affecting\n",
      "Fake -1.3083507950398559 furthermore\n",
      "Fake -1.2973087134150798 urged\n",
      "Fake -1.2811519386062502 claiming\n",
      "Fake -1.2753521650002329 check\n",
      "Fake -1.261784149332416 website\n",
      "Fake -1.186786211200096 nab\n",
      "Fake -1.1508625364995273 forbidden\n",
      "Fake -1.1233846696117782 country\n",
      "Fake -1.1032882375048874 results\n",
      "Fake -1.1014203343810767 mr\n",
      "Fake -1.0947441640749305 information\n",
      "Fake -1.0604227854275938 sharif\n",
      "Fake -1.0246095278033158 israel\n",
      "Fake -1.014792637005093 travelling\n",
      "Fake -0.9811139594596564 islamabad\n",
      "\n",
      "True  1.9170665519270231 effecting\n",
      "True  1.6103342878480431 wing\n",
      "True  1.5684126466941275 press\n",
      "True  1.5468660886942263 adds\n",
      "True  1.514075838725636 contrary\n",
      "True  1.3964231163529874 army\n",
      "True  1.2331245323219102 services\n",
      "True  1.2156979362233291 sunday\n",
      "True  1.1644056673039238 rawalpindi\n",
      "True  1.1607258803303495 military\n",
      "True  1.0595677631548381 categorically\n",
      "True  1.05497347453255 points\n",
      "True  1.028424280945132 claim\n",
      "True  1.0031354885105856 government\n",
      "True  0.9698535693676621 chaudhry\n",
      "True  0.9697167240721929 foreign\n",
      "True  0.9619170592226431 area\n",
      "True  0.9585332759635116 minster\n",
      "True  0.9469735303920559 strongly\n",
      "True  0.9380018130269038 federal\n",
      "True  0.9326767874402924 deal\n",
      "True  0.9037859292031483 defense\n",
      "True  0.9019998150381177 mee\n",
      "True  0.8978372572830613 chohan\n",
      "True  0.8855451865941013 department\n",
      "True  0.8793746436841253 sindh\n",
      "True  0.8713712862912115 tehrik\n",
      "True  0.8631454309282875 shah\n",
      "True  0.8605015711227816 inter\n",
      "True  0.8555134911164086 channels\n"
     ]
    }
   ],
   "source": [
    "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=100):\n",
    "    \"\"\"\n",
    "    See: https://stackoverflow.com/a/26980472\n",
    "    \n",
    "    Identify most important features if given a vectorizer and binary classifier. Set n to the number\n",
    "    of weighted features you would like to show. (Note: current implementation merely prints and does not \n",
    "    return top classes.)\n",
    "    \"\"\"\n",
    "\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "\n",
    "    for coef, feat in topn_class1:\n",
    "        print(class_labels[0], coef, feat)\n",
    "\n",
    "    print()\n",
    "\n",
    "    for coef, feat in reversed(topn_class2):\n",
    "        print(class_labels[1], coef, feat)\n",
    "\n",
    "\n",
    "most_informative_feature_for_binary_classification(tfidf_vectorizer, linear_clf, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-4.4807466538476275, 'saiful'),\n",
       " (-4.630091942399948, 'pakistani'),\n",
       " (-5.090743466075403, 'minister'),\n",
       " (-5.106829603827028, 'government'),\n",
       " (-5.599797610193011, 'khan'),\n",
       " (-5.794585935752096, 'prince'),\n",
       " (-5.849848614427145, 'china'),\n",
       " (-5.957737576438331, 'policemen'),\n",
       " (-6.023120335701182, 'court'),\n",
       " (-6.064505551864037, 'peoples'),\n",
       " (-6.0930789243080925, 'islamabad'),\n",
       " (-6.107677723729245, 'country'),\n",
       " (-6.152798159009715, 'imran'),\n",
       " (-6.18405070251382, 'chief'),\n",
       " (-6.2496479849996325, 'media'),\n",
       " (-6.2496479849996325, 'foreign'),\n",
       " (-6.266742418358933, 'news'),\n",
       " (-6.266742418358933, 'billion'),\n",
       " (-6.284134161070802, 'economic'),\n",
       " (-6.3018337381702025, 'tlv')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "sorted(zip(clf.coef_[0], feature_names), reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-10.327185428905352, '025'),\n",
       " (-10.327185428905352, '09'),\n",
       " (-10.327185428905352, '0yk'),\n",
       " (-10.327185428905352, '1000'),\n",
       " (-10.327185428905352, '10000'),\n",
       " (-10.327185428905352, '101'),\n",
       " (-10.327185428905352, '10m'),\n",
       " (-10.327185428905352, '116'),\n",
       " (-10.327185428905352, '118'),\n",
       " (-10.327185428905352, '119'),\n",
       " (-10.327185428905352, '120'),\n",
       " (-10.327185428905352, '122'),\n",
       " (-10.327185428905352, '12800'),\n",
       " (-10.327185428905352, '13th'),\n",
       " (-10.327185428905352, '140m'),\n",
       " (-10.327185428905352, '144'),\n",
       " (-10.327185428905352, '145'),\n",
       " (-10.327185428905352, '151'),\n",
       " (-10.327185428905352, '159'),\n",
       " (-10.327185428905352, '1600')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### Most fake\n",
    "sorted(zip(clf.coef_[0], feature_names))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('00', -9.228573140237243)\n"
     ]
    }
   ],
   "source": [
    "tokens_with_weights = sorted(list(zip(feature_names, clf.coef_[0])))\n",
    "for i in tokens_with_weights:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
